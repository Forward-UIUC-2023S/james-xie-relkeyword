# Keyword Intelligence Service: Related Keyword Recommendation

## Overview

This module takes a corpus of documents and an initial keyword as input and extracts keyphrase recommendations
to boost the quality of document search. It contains three main components: 

* Code for a frontend Chrome extension that reads any user input text field within Chrome and displays keyphrase recommendations withih 
## Setup

1. Make sure you have the following versions for Python and Pip:
Python version 3.97. 
   PIP version 22.0.4

2. To install required python dependencies, run 
```
pip install -r requirements.txt
```

### To install relkeyword package:
1. pip install relkeyword

### To install and run Chrome Extension:
Backend:
1. cd backend
2. python3 manage.py runserver

Chrome Extension:
1. Navigate to chrome://extensions in a new Google Chrome Tab
2. Click "Load Unpacked"
3. Select the extension folder in this module

To use Extension
1. Click the textbox that contains the word that you want to receive keyword suggestions for
2. Open the extension tab. There should be a list of buttons corresponding to the keyphrase recommendations for the initial keyword.


Structure of module:
```
james-xie-relatedkeyword/
    - requirements.txt
    - data/ 
        -- Grants-20230219.csv
        -- other files used during testing
    - backend/
        -- manage.py
        -- backend/
            --- views.py
    - extension/
    - relkeyword/
        -- src/relkeyword/
            --- CorpusAnalyzer.py
            --- KeywordSuggester.py
    - relkeyword_dir/
        -- grants/
            --- sorted_semantic_related.json
            --- sorted_semantic_similar.json
             
```


* `backend/`: Contains all the code necessary to run a Django Server for the Chrome extension to send requests to
* `relkeyword/`: Directory contains code for Python Package module relkeyword
* `extension/`: Contains extension that can be loaded to Chrome 
* `relkeyword_dir/`: Directory that is created when the CorpusAnalyzer class is run
* `relkeyword/src/relkeyword/CorpusAnalyzer.py`: contains class and function declarations for CorpusAnalyzer, which takes a corpus as input and generates the following:
    - `relkeyword_dir/<name of corpus>/candidate_keyphrases.txt`: List of candidate keyphrases extracted from each individual document using YAKE or EmbedRank
    - `relkeyword_dir/<name of corpus>/sorted_semantic_related.json`: Json dictionary mapping from each candidate keyphrase to the top semantically related keywords derived from co-occurrence
    - `relkeyword_dir/<name of corpus>/sorted_semantic_similar.json`: JSON dictionary mapping from each candidate keyphrase to the top semantically similar keywords derived from embeddings
* `relkeyword/src/relkeyword/KeywordSuggester.py`: KeywordSuggester class takes output files derived from CorpusAnalyzer class to output keyword recommendations as well as a corresponding sentence justification
* `data/Grants-20230219.csv`: Grant Corpus where preliminary testing was conducted

### Important 
Go to [our shared google Drive space](https://drive.google.com/drive/folders/1rxPAdGTVcl-Xo6uuFovdKcCw5_FEaXIC?usp=sharing) and create a folder with the format `FirstnameLastName-Projectname` (e.g. `AshutoshUkey-KeywordTrie`). In here, make sure to include a zipped copy of any data files related to your module (including `.sql` dumps of necessary databases) as well as a backup zipped copy of your Github repo (i.e. all the files you upload to Github).



## Functional Design (Usage)
After installing relkeyword Python package, the CorpusAnalyzer and KeywordSuggester classes can be used as follows:

* To import package:
```python
from relkeyword import CorpusAnalyzer, KeywordSuggester
```
* CorpusAnalyer class is instantiated by passing two arguments: 
```python
    c = CorpusAnalyzer.CorpusAnalyzer(list documents, str CorpusName)
```
where documents is a list of strings and each string corresponds to a document in the input corpus.

* To retrieve candidate keyphrases using YAKE:
```python
c.generate_candidate_keyphrases(threshold = 5)
```
where threshold refers to the minimum number of documents in the corpus that each keyword should be selected as a keyphrase to be considered a candidate keyphrase for the keyword suggestion service.

* Once canddiate keyphrases are retrieved we can retrieve the related and similar keywords as follows:
```python
c.generate_related_keywords()
c.generate_semantic_similar()
```
If you have a list of keywords you would like to use instead of the ones generated by YAKE, you can pass the list of keywords as an argument:
```python
c.generate_related_keywords(list candidate_keyphrases)
```

* This should all result in a local relkeyword_dir directory being created with all the necessary files for the KeywordSuggester class. The KeywordSuggester class is instatiated by passing this path as an argument:

```python
kw_suggester = KeywordSuggester.KeywordSuggester("relkeyword_dir/<name of corpus>/")
```

* To extract a related keyword use the following line of code:
```python
kw_suggester.retrieve_related_words("children")
```
* To extract a sentence containing the keyword and the related keyword:
```python
kw_suggester.retrieve_sentence("children", "youth")
```
## Demo video
https://drive.google.com/file/d/1Q547fdhSeuhRXetxQTvZ7jaXCp9Bd-7p/view?usp=share_link


## Algorithmic Design 

We first generate a set of candidate keyphrases from the document corpus. Since EmbedRank requires us to use a running coreNLP server in the background, we used YAKE to make packaging easier. 

From the list of candidate keyphrases, we then first train embeddings using Phrase-BERT for each of the candidate keyphrases. To find the most semantically similar keyphrases, we take the top-k most similar phrases using the cosine similarity of their embeddings. We then use resnik's selectional metric to find the degree to which two keyphrases are likely to appear in the same context for each pair of candidate keyphrases. Using this metric, we then find the top-k most related keyphrases.

Once we have a list of semantically similar and semantically related keyphrases, we are able to recommend keywords given an initial keyword based on the document corpus. To extract a sentence justification, we retrieve a list of all the sentences that contain both the initial keyword and the related keyword suggestion. We then filter out the sentences by only selecting the sentences where the two words appear within a certain window length. Finally, we rank the remaining sentences by TF-IDF and select the highest ranked score.



![design architecture](https://github.com/Forward-UIUC-2023S/james-xie-relkeyword/blob/main/ModelArchitecture.png)



## Issues and Future Work

The time for the CorpusAnalyzer to run on a very large document corpus can take almost a full day. An area for improvement would be to figure out how to make this faster, however this is pre-processing so it is not as essential. 

Currently, the embedding model used is the pre-trained Phrase-BERT model trained on the Books3 Corpus. Since we want to capture the semantics of the corpus as better context, training the embeddings on each individual corpus may serve as an improvement. However, difficulty arises because the Phrase-BERT model requires training triplets to fine-tune the BERT model, with a positive and negative pair corresponding to each pair. Therefore, code would need to be written to automaticallly generate these training examples from a corpus to train the Phrase-BERT model. 

## Change log

Spring 2023 (James Xie)
- Initial Commit
- Created CorpusAnalyzer and KeywordSuggester class
## References 
include links related to datasets and papers describing any of the methodologies models you used. E.g. 

* Dataset: https://www.kaggle.com/Cornell-University/arxiv 
* BERT paper: Jacob Devlin, Ming-Wei Chang, Kenton Lee, & Kristina Toutanova. (2019). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.

